{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **[HiFiPLN ](https://utau.pl/hifipln/)**\n",
        "Multispeaker Community Vocoder Model for DiffSinger\n",
        "\n",
        "\n",
        "___\n",
        "Last update: 02/04/2024\n",
        "\n",
        "\n",
        "#### **Notebook made by [me](https://github.com/Airi-Lin)**\n",
        "#### **Inspired by the [Diffsinger_colab_notebook](https://github.com/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7)**\n",
        "\n",
        "#### **Check the link on HiFiPLN to see the awesome work made! Without them, this wouldnt be possible**\n",
        "Version: **1.0.0**\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "-XiDpY3fChnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "_M1RLMGZ1XRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Make sure that your colab session is connected to a GPU.**\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ywb65rwvzzo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Download repo and install requirements**\n",
        "from IPython.display import Audio, display, HTML, clear_output\n",
        "%cd /content/\n",
        "!git clone https://github.com/Scarfmonster/HiFiPLN/\n",
        "clear_output()\n",
        "%cd /content/HiFiPLN\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget \"https://dl.utau.pl/dl.php?name=checkpoint&file=hifipln&version=1.0&type=7z\" -O \"hifipln_1.0.7z\"\n",
        "!mkdir /content/HiFiPLN/ckpt\n",
        "!7za -bso0 -y x \"hifipln_1.0.7z\" -o/content/HiFiPLN/ckpt\n",
        "!rm \"/content/HiFiPLN/hifipln_1.0.7z\"\n",
        "!wget -O kururin.mp3 https://www.myinstants.com/media/sounds/honkai-herta-hudurin-kuru-kuru.mp3\n",
        "clear_output()\n",
        "\n",
        "\n",
        "display(Audio(filename='/content/HiFiPLN/kururin.mp3', autoplay=True, rate=44100))\n",
        "\n",
        "\n",
        "display(HTML(\n",
        "      '''\n",
        "      <marquee ><b>Installation successfully!!</b></marquee>\n",
        "      <div style = \"display: flex; justify-content: left; align-items: left;\">\n",
        "        <img src=\"https://media.tenor.com/7lHdnabfyTQAAAAi/herta-kurukuru.gif\", width=249, height=206>\n",
        "      </div>\n",
        "      '''))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GlhJj-bhyH7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yJd5_81SxhfC"
      },
      "outputs": [],
      "source": [
        "#@markdown **OPTIONAL**\n",
        "#@markdown Mount Google Drive to this notebook if you have your dataset there\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "DI1Bciz915IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown val_ratio is the percentage of the dataset to be used as validation, going to 0 to 1, being 1 a 100%\n",
        "dataset_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import random\n",
        "!mkdir /content/HiFiPLN/dataset/valid/\n",
        "\n",
        "!python dataset-utils/split.py --length 1 -sr 44100 -o \"dataset/train\" {dataset_path}\n",
        "\n",
        "\n",
        "# Set the paths of the train and validation folders\n",
        "train_path = \"/content/HiFiPLN/dataset/train\"\n",
        "val_path = \"/content/HiFiPLN/dataset/valid\"\n",
        "\n",
        "# Set the fraction of files to move to the validation folder\n",
        "val_ratio = 0.15 # @param {type:\"slider\", min:0.05, max:1.0, step:0.05}\n",
        "\n",
        "# List all the wav files in the train folder\n",
        "wav_files = [f for f in os.listdir(train_path) if f.endswith(\".wav\")]\n",
        "\n",
        "# Shuffle the files\n",
        "random.shuffle(wav_files)\n",
        "\n",
        "# Calculate the number of files to move\n",
        "val_size = int(len(wav_files) * val_ratio)\n",
        "\n",
        "# Move the files to the validation folder\n",
        "for i in range(val_size):\n",
        "  file = wav_files[i]\n",
        "  src = os.path.join(train_path, file)\n",
        "  dst = os.path.join(val_path, file)\n",
        "  os.rename(src, dst)\n",
        "\n",
        "# Print the number of files in each folder\n",
        "print(f\"Train folder: {len(os.listdir(train_path))} files\")\n",
        "print(f\"Validation folder: {len(os.listdir(val_path))} files\")\n",
        "\n",
        "\n",
        "!python preproc.py --path dataset --config \"configs/hifipln.yaml\""
      ],
      "metadata": {
        "id": "k4POt_yt-U3x",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tuning**"
      ],
      "metadata": {
        "id": "NkqgBG811SR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown *Fine-Tuning only available due to possible Colab limits*\n",
        "\n",
        "\n",
        "validation_steps = 500 # @param {type:\"slider\", min:500, max:10000, step:500}\n",
        "learning_rate = 0.00001 #@param {type: \"number\"}\n",
        "batch_size = 8 # @param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "config = OmegaConf.load(\"configs/hifipln-finetune.yaml\")\n",
        "config.val_check = validation_steps\n",
        "config.lr = learning_rate\n",
        "config.dataloader.train.batch_size = batch_size\n",
        "config.finetune = \"ckpt/hifipln_1.0.ckpt\"\n",
        "config.dataloader.train.num_workers=2\n",
        "config.dataloader.valid.num_workers=2\n",
        "OmegaConf.save(config, \"configs/config.yaml\")\n",
        "\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/HiFiPLN/logs/HiFiPLN\n",
        "\n",
        "!python train.py --config \"configs/config.yaml\"\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dBQ_ttWP1ghd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export for OpenUTAU**"
      ],
      "metadata": {
        "id": "o-vGP7XBB4dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Checkpoint = \"\" # @param {type:\"string\"}\n",
        "#@markdown Output should be found on out/hifipln\n",
        "\n",
        "!python export.py --config configs/hifipln.yaml --output out/hifipln --model {Checkpoint}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aI51G68nB7lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}